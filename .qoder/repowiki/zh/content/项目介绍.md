# 项目介绍

<cite>
**本文档引用文件**  
- [README.md](file://README.md)
</cite>

## 目录
1. [引言](#引言)
2. [项目概述](#项目概述)
3. [核心研究问题](#核心研究问题)
   - [RQ1：如何构建面向网络安全的领域专用大语言模型？](#rq1如何构建面向网络安全的领域专用大语言模型)
   - [RQ2：大语言模型在网络安全中的潜在应用有哪些？](#rq2大语言模型在网络安全中的潜在应用有哪些)
   - [RQ3：大语言模型在网络安全应用中的进一步研究方向是什么？](#rq3大语言模型在网络安全应用中的进一步研究方向是什么)
4. [目标受众与受益方式](#目标受众与受益方式)
5. [基础概念与术语解释](#基础概念与术语解释)
6. [项目更新与社区贡献](#项目更新与社区贡献)

## 引言
我们很高兴推出《当大语言模型遇见网络安全：一项系统性文献综述》，这是一份关于大语言模型（LLMs）在网络安全领域应用的全面概述。

本项目旨在探讨三个关键问题：
- RQ1：如何构建面向网络安全的领域专用大语言模型？
- RQ2：大语言模型在网络安全中的潜在应用有哪些？
- RQ3：大语言模型在网络安全应用中的现有挑战和未来研究方向是什么？

![table_1](figs/table1.png)

**Section sources**
- [README.md](file://README.md#L45-L47)

## 项目概述
本项目是一项系统性文献综述，涵盖了对超过300篇相关研究工作的分析，涉及25个以上的大语言模型和10多个下游应用场景。项目通过整理和分类这些研究论文，为研究人员、开发者和学生提供了一个清晰、结构化的知识体系。

项目定期更新，例如，截至2025年2月28日，新增了33篇论文。此外，项目还包含了每篇论文的发表场所信息，以增强其学术价值。

![statistic](figs/statistic.png)

**Section sources**
- [README.md](file://README.md#L63-L65)

## 核心研究问题

### RQ1：如何构建面向网络安全的领域专用大语言模型？
本部分探讨了如何为网络安全领域定制和优化大语言模型，主要分为两个方面：评估基准和微调模型。

#### 网络安全评估基准
项目整理了一系列用于评估大语言模型在网络安全领域能力的基准数据集，例如：
- **Primus**：一个开源的网络安全大语言模型训练数据集集合。
- **SecBench**：一个全面的多维度基准测试数据集。
- **CS-Eval**：一个针对网络安全的综合性大语言模型基准。
- **Purple Llama CyberSecEval**：一个用于安全编码的基准。

这些基准为衡量模型在威胁情报、漏洞检测等任务上的表现提供了标准。

#### 领域专用大语言模型的微调
项目还收录了大量通过微调技术构建的面向网络安全的专用大语言模型，例如：
- **ELTEX**：一个用于领域驱动合成数据生成的框架。
- **Hackphyr**：一个用于网络环境安全的本地微调大语言模型代理。
- **CyberPal.AI**：一个通过专家驱动的网络安全指令来增强大语言模型的项目。
- **Owl**：一个用于IT运维的大语言模型。

这些模型通过在特定网络安全数据上进行微调，显著提升了在专业任务上的性能。

**Section sources**
- [README.md](file://README.md#L65-L148)

### RQ2：大语言模型在网络安全中的潜在应用有哪些？
本部分详细阐述了大语言模型在网络安全中的多种应用场景。

#### 威胁情报
大语言模型被用于自动化威胁情报分析，例如：
- 自动化生成威胁情报报告（AGIR）。
- 利用检索增强生成（RAG）技术构建网络安全知识图谱（CTINEXUS）。
- 将NIDS规则与MITRE ATT&CK技术进行标签化（Labeling NIDS Rules）。
- 通过聊天机器人（如IntellBot）提供威胁知识交付。

#### Fuzzing
大语言模型在模糊测试中扮演着重要角色，例如：
- 辅助生成种子（Harnessing LLMs for Seed Generation）。
- 指导协议模糊测试（Large language model guided protocol fuzzing）。
- 生成模糊测试驱动程序（Prompt Fuzzing for Fuzz Driver Generation）。
- 用于深度学习库的零样本模糊测试（Large Language Models are Zero-Shot Fuzzers）。

#### 漏洞检测
大语言模型被广泛应用于软件漏洞的检测与定位，例如：
- 开发用于漏洞检测的评估框架（VulnLLMEval）。
- 利用检索增强生成（RAG）技术增强漏洞检测（Vul-RAG）。
- 在反编译的二进制文件中进行漏洞分析（Enhancing Reverse Engineering）。
- 检测智能合约中的逻辑漏洞（GPTScan）。

#### 不安全代码生成
该领域关注大语言模型生成代码的安全性，例如：
- 评估由大语言模型生成的代码是否真正安全（Is Your AI-Generated Code Really Safe?）。
- 分析中性提示是否会产生不安全代码（Do Neutral Prompts Produce Insecure Code?）。
- 研究GitHub Copilot代码贡献的安全性（Asleep at the Keyboard?）。

#### 程序修复
大语言模型在自动修复安全漏洞方面展现出巨大潜力，例如：
- 实现迭代式自动化漏洞修复（LLM4CVE）。
- 结合程序分析进行混合自动程序修复（Hybrid Automated Program Repair）。
- 使用强化学习和语义奖励进行漏洞修复（LLM-Powered Code Vulnerability Repair）。
- 评估大语言模型修补安全问题的能力（Can LLMs Patch Security Issues?）。

#### 异常检测
大语言模型被用于检测各种网络异常，例如：
- 基于上下文的Android恶意软件检测与分类（LAMD）。
- 使用大语言模型进行日志分析（LogLLM）。
- 检测钓鱼邮件（Large Language Models Spot Phishing Emails）。
- 检测云设备中的网络入侵（XG-NID）。

#### 大语言模型辅助攻击
本部分探讨了大语言模型被用于攻击的双刃剑效应，例如：
- 构建全自动的渗透测试工具（PentestGPT, RapidPen）。
- 生成钓鱼邮件和恶意软件（RatGPT）。
- 执行多阶段网络攻击（On the Feasibility of Using LLMs to Execute Multistage Network Attacks）。
- 生成对抗性攻击载荷（From Text to MITRE Techniques）。

#### 其他应用
还包括一些新兴和跨领域的应用，例如：
- 用于IT运维管理（Empowering AIOps）。
- 用于物联网安全（ChatIoT）。
- 用于构建交互式蜜罐系统（LLM Honeypot）。
- 用于二进制反汇编（LLM4Decompile）。

**Section sources**
- [README.md](file://README.md#L152-L741)

### RQ3：大语言模型在网络安全应用中的进一步研究方向是什么？
本项目的未来研究方向聚焦于“Agent4Cybersecurity”，即利用大语言模型代理（LLM Agents）来实现更高级的网络安全自动化。

- **多代理协作**：研究多个大语言模型代理如何协作进行渗透测试（BreachSeek）和事件响应（Multi-Agent Collaboration in Incident Response）。
- **自主攻击与防御**：探索代理如何自主利用零日漏洞（Teams of LLM Agents can Exploit Zero-Day Vulnerabilities）以及如何防御此类攻击。
- **智能代理框架**：开发如TaskWeaver、ToolLLM等框架，使大语言模型能够调用真实世界的API，执行复杂任务。
- **安全风险评估**：建立基准来评估大语言模型代理的安全风险意识（R-Judge）。

**Section sources**
- [README.md](file://README.md#L746-L881)

## 目标受众与受益方式
本项目的主要目标受众包括：
- **研究人员**：可以快速定位特定主题（如“RAG在漏洞检测中的应用”或“LLM在威胁情报中的自动化”）的最新研究论文，了解研究趋势和空白，为自己的研究提供坚实的基础。
- **开发者**：可以从项目中获取应用灵感，例如，如何利用大语言模型构建一个自动化的漏洞修复工具，或如何设计一个基于RAG的威胁情报分析系统。
- **学生**：可以将本项目作为学习大语言模型与网络安全交叉领域的入门指南，通过阅读精选论文来系统性地掌握相关知识。

**Section sources**
- [README.md](file://README.md#L45-L47)

## 基础概念与术语解释
为帮助初学者理解，以下是一些关键术语的解释：
- **大语言模型 (LLM)**：一种能够理解、生成和推理人类语言的先进人工智能模型，如GPT系列。
- **网络安全基础**：保护计算机系统、网络和数据免受数字攻击、损害或未经授权访问的实践。
- **文献综述的价值**：系统性地收集、评估和总结现有研究，以提供对某一领域的全面、无偏见的概述，帮助识别研究趋势、差距和未来方向。
- **Fuzzing (模糊测试)**：一种通过向程序输入大量随机或半随机数据来发现软件漏洞的自动化测试技术。
- **TTPs (战术、技术和程序)**：描述网络攻击者行为模式的框架，常用于威胁情报和攻击溯源。
- **RAG (检索增强生成)**：一种技术，通过从外部知识库检索相关信息并将其作为上下文提供给大语言模型，从而提高其生成内容的准确性和事实性。

**Section sources**
- [README.md](file://README.md#L45-L47)

## 项目更新与社区贡献
本项目通过GitHub进行维护，并鼓励社区贡献。其更新机制透明，定期发布新收录的论文。社区成员可以通过提交Pull Request（PR）来推荐新的相关研究论文，从而共同完善这个知识库。项目还强调了链接到外部学术资源（如arXiv论文链接）的重要性，方便用户直接访问原始文献。

**Section sources**
- [README.md](file://README.md#L2-L3)