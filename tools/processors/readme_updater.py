import re
import os
from typing import List, Dict, Optional
from datetime import datetime
import logging

from .paper_processor import ProcessedPaper

class ReadmeUpdater:
    """README.mdæ–‡ä»¶æ›´æ–°å™¨"""
    
    def __init__(self, readme_path: str = "README.md", language: str = "en"):
        self.readme_path = readme_path
        self.language = language  # "en" æˆ– "zh"
        self.logger = logging.getLogger(__name__)
        
        # è‹±æ–‡åˆ°ä¸­æ–‡åˆ†ç±»åç§°æ˜ å°„
        self.en_to_zh_mapping = {
            "Cybersecurity Evaluation Benchmarks": "ç½‘ç»œå®‰å…¨è¯„æµ‹åŸºå‡†",
            "Fine-tuned Domain LLMs for Cybersecurity": "ç½‘ç»œå®‰å…¨é¢†åŸŸå¾®è°ƒå¤§æ¨¡å‹",
            "Threat Intelligence": "å¨èƒæƒ…æŠ¥",
            "FUZZ": "æ¨¡ç³Šæµ‹è¯•ï¼ˆFUZZï¼‰",
            "Vulnerabilities Detection": "æ¼æ´æ£€æµ‹",
            "Insecure code Generation": "ä¸å®‰å…¨ä»£ç ç”Ÿæˆ",
            "Program Repair": "ç¨‹åºä¿®å¤",
            "Anomaly Detection": "å¼‚å¸¸æ£€æµ‹",
            "LLM Assisted Attack": "å¤§æ¨¡å‹è¾…åŠ©æ”»å‡»",
            "Others": "å…¶ä»–åº”ç”¨",
            "Further Research: Agent4Cybersecurity": "è¿›ä¸€æ­¥ç ”ç©¶ï¼šAgent4Cybersecurityï¼ˆç½‘ç»œå®‰å…¨æ™ºèƒ½ä½“ï¼‰"
        }
        
        # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(readme_path):
            raise FileNotFoundError(f"READMEæ–‡ä»¶ä¸å­˜åœ¨: {readme_path}")
    
    def add_papers_to_category(self, papers: List[ProcessedPaper], 
                             category: str, subcategory: str) -> bool:
        """å°†è®ºæ–‡æ·»åŠ åˆ°æŒ‡å®šåˆ†ç±»ä¸­"""
        try:
            with open(self.readme_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ‰¾åˆ°å¯¹åº”çš„åˆ†ç±»éƒ¨åˆ†
            section_pattern = self._build_section_pattern(subcategory)
            match = re.search(section_pattern, content, re.MULTILINE | re.DOTALL)
            
            if not match:
                self.logger.warning(f"æœªæ‰¾åˆ°åˆ†ç±»: {subcategory}")
                return False
            
            # è·å–ç°æœ‰è®ºæ–‡ç¼–å·
            existing_numbers = self._get_existing_paper_numbers(match.group(0))
            next_number = max(existing_numbers) + 1 if existing_numbers else 1
            
            # ç”Ÿæˆæ–°è®ºæ–‡æ¡ç›®
            new_entries = []
            for paper in papers:
                entry = self._format_paper_entry(paper, next_number)
                new_entries.append(entry)
                next_number += 1
                self.logger.info(f"æ·»åŠ è®ºæ–‡: {paper.title[:50]}... åˆ°åˆ†ç±» {subcategory}")
            
            # æ‰¾åˆ°æ’å…¥ä½ç½®ï¼ˆè¯¥åˆ†ç±»çš„æœ€åä¸€ç¯‡è®ºæ–‡åï¼‰
            insertion_point = self._find_insertion_point(content, subcategory)
            
            if insertion_point == -1:
                self.logger.error(f"æ— æ³•æ‰¾åˆ°åˆ†ç±» {subcategory} çš„æ’å…¥ä½ç½®")
                return False
            
            # æ’å…¥æ–°æ¡ç›®
            new_content = (
                content[:insertion_point] + 
                '\n\n' + '\n\n'.join(new_entries) + 
                content[insertion_point:]
            )
            
            # å†™å›æ–‡ä»¶
            with open(self.readme_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            self.logger.info(f"æˆåŠŸæ·»åŠ  {len(new_entries)} ç¯‡è®ºæ–‡åˆ° {subcategory}")
            return True
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°READMEå¤±è´¥: {e}")
            return False
    
    def _build_section_pattern(self, subcategory: str) -> str:
        """æ„å»ºåˆ†ç±»ç« èŠ‚çš„æ­£åˆ™è¡¨è¾¾å¼"""
        # æ ¹æ®è¯­è¨€é€‰æ‹©åˆé€‚çš„åˆ†ç±»åç§°
        if self.language == "zh" and subcategory in self.en_to_zh_mapping:
            target_subcategory = self.en_to_zh_mapping[subcategory]
        else:
            target_subcategory = subcategory
        
        # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
        escaped_subcategory = re.escape(target_subcategory)
        
        # åŒ¹é…markdownæ ‡é¢˜
        pattern = f"####\\s+{escaped_subcategory}\\s*\n(.*?)(?=\n####|\n###|\n##|\\Z)"
        return pattern
    
    def _get_existing_paper_numbers(self, section_content: str) -> List[int]:
        """è·å–å·²å­˜åœ¨çš„è®ºæ–‡ç¼–å·"""
        numbers = []
        
        # åŒ¹é…è®ºæ–‡æ¡ç›®ç¼–å· (å¦‚: "1. Title")
        pattern = r'^\s*(\d+)\.\s+'
        matches = re.findall(pattern, section_content, re.MULTILINE)
        
        for match in matches:
            try:
                numbers.append(int(match))
            except ValueError:
                continue
        
        return numbers
    
    def _find_insertion_point(self, content: str, subcategory: str) -> int:
        """æ‰¾åˆ°è®ºæ–‡æ’å…¥ä½ç½®"""
        # æ ¹æ®è¯­è¨€é€‰æ‹©åˆé€‚çš„åˆ†ç±»åç§°
        if self.language == "zh" and subcategory in self.en_to_zh_mapping:
            target_subcategory = self.en_to_zh_mapping[subcategory]
        else:
            target_subcategory = subcategory
        
        # é¦–å…ˆæ‰¾åˆ°subcategoryçš„ä½ç½®
        subcategory_pattern = f"####\\s+{re.escape(target_subcategory)}"
        subcategory_match = re.search(subcategory_pattern, content)
        
        if not subcategory_match:
            return -1
        
        start_pos = subcategory_match.end()
        
        # ä»subcategoryå¼€å§‹ï¼Œæ‰¾åˆ°ä¸‹ä¸€ä¸ªåŒçº§æˆ–æ›´é«˜çº§æ ‡é¢˜çš„ä½ç½®
        next_section_pattern = r'\n(####|###|##)\s+'
        next_section_match = re.search(next_section_pattern, content[start_pos:])
        
        if next_section_match:
            # åœ¨ä¸‹ä¸€ä¸ªsectionä¹‹å‰æ’å…¥
            return start_pos + next_section_match.start()
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸‹ä¸€ä¸ªsectionï¼Œåœ¨æ–‡ä»¶æœ«å°¾æ’å…¥
            return len(content)
    
    def _format_paper_entry(self, paper: ProcessedPaper, number: int) -> str:
        """æ ¼å¼åŒ–è®ºæ–‡æ¡ç›®"""
        date_str = paper.publish_date.strftime("%Y.%m.%d")
        
        # æ ¹æ®è¯­è¨€é€‰æ‹©åˆé€‚çš„æ ‡é¢˜
        if self.language == "zh":
            # ä¸­æ–‡ç‰ˆä¼˜å…ˆä½¿ç”¨ä¸­æ–‡æ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨è‹±æ–‡æ ‡é¢˜
            title = getattr(paper, 'chinese_title', paper.title) or paper.title
            link_text = "è®ºæ–‡é“¾æ¥"
        else:
            # è‹±æ–‡ç‰ˆä½¿ç”¨è‹±æ–‡æ ‡é¢˜
            title = paper.title
            link_text = "Paper Link"
        
        # æ¸…ç†æ ‡é¢˜ä¸­å¯èƒ½å¯¼è‡´markdownæ ¼å¼é—®é¢˜çš„å­—ç¬¦
        clean_title = title.replace('[', '\\[').replace(']', '\\]')
        
        # æ ¹æ®è¯­è¨€æ ¼å¼åŒ–æ¡ç›®
        if self.language == "zh":
            entry = f"{number}. {clean_title} ï½œ *{paper.venue}* ï½œ {date_str} ï½œ [<u>{link_text}</u>]({paper.url})"
        else:
            entry = f"{number}. {clean_title} | *{paper.venue}* | {date_str} | [<u>{link_text}</u>]({paper.url})"
        
        return entry
    
    def update_statistics(self, new_papers_count: int, total_papers_count: Optional[int] = None) -> bool:
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        try:
            with open(self.readme_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ›´æ–°æœ€æ–°æ›´æ–°æ—¥æœŸ
            today = datetime.now().strftime("%Y-%m-%d")
            
            # åœ¨ğŸ”¥ Updateséƒ¨åˆ†æ·»åŠ æ–°çš„æ›´æ–°è®°å½•
            updates_pattern = r'(## ğŸ”¥ Updates\n)'
            new_update = f"ğŸ“†[{today}] é€šè¿‡è‡ªåŠ¨åŒ–å·¥å…·æ–°å¢ *{new_papers_count}* ç¯‡è®ºæ–‡ã€‚\n\n"
            
            updated_content = re.sub(
                updates_pattern, 
                f"\\1{new_update}", 
                content, 
                count=1
            )
            
            # å¦‚æœæä¾›äº†æ€»è®ºæ–‡æ•°ï¼Œæ›´æ–°Featureséƒ¨åˆ†çš„ç»Ÿè®¡
            if total_papers_count:
                features_pattern = r'(\(2024\.08\.20\) Our study encompasses an analysis of over )\d+( works)'
                updated_content = re.sub(
                    features_pattern,
                    f"\\1{total_papers_count}\\2",
                    updated_content
                )
            
            # å†™å›æ–‡ä»¶
            with open(self.readme_path, 'w', encoding='utf-8') as f:
                f.write(updated_content)
            
            self.logger.info(f"æ›´æ–°ç»Ÿè®¡ä¿¡æ¯: æ–°å¢ {new_papers_count} ç¯‡è®ºæ–‡")
            return True
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return False
    
    def backup_readme(self) -> str:
        """å¤‡ä»½READMEæ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = f"{self.readme_path}.backup_{timestamp}"
        
        try:
            with open(self.readme_path, 'r', encoding='utf-8') as src:
                with open(backup_path, 'w', encoding='utf-8') as dst:
                    dst.write(src.read())
            
            self.logger.info(f"READMEå¤‡ä»½åˆ›å»º: {backup_path}")
            return backup_path
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºå¤‡ä»½å¤±è´¥: {e}")
            return ""
    
    def validate_readme_structure(self) -> bool:
        """éªŒè¯READMEæ–‡ä»¶ç»“æ„"""
        try:
            with open(self.readme_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ ¹æ®è¯­è¨€é€‰æ‹©éœ€è¦æ£€æŸ¥çš„ç« èŠ‚
            if self.language == "zh":
                required_sections = [
                    "## ğŸ”¥ æ›´æ–°æ—¥å¿—",
                    "## ğŸŒˆ å¼•è¨€", 
                    "## ğŸš© ç ”ç©¶ç‰¹æ€§",
                    "## ğŸŒŸ æ–‡çŒ®æ±‡æ€»",
                    "### RQ1ï¼š",
                    "### RQ2ï¼š",
                    "### RQ3ï¼š"
                ]
            else:
                required_sections = [
                    "## ğŸ”¥ Updates",
                    "## ğŸŒˆ Introduction", 
                    "## ğŸš© Features",
                    "## ğŸŒŸ Literatures",
                    "### RQ1:",
                    "### RQ2:",
                    "### RQ3:"
                ]
            
            missing_sections = []
            for section in required_sections:
                if section not in content:
                    missing_sections.append(section)
            
            if missing_sections:
                self.logger.warning(f"READMEç¼ºå°‘å¿…è¦ç« èŠ‚: {missing_sections}")
                return False
            
            self.logger.info("READMEç»“æ„éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            self.logger.error(f"READMEç»“æ„éªŒè¯å¤±è´¥: {e}")
            return False
    
    def count_existing_papers(self) -> Dict[str, int]:
        """ç»Ÿè®¡ç°æœ‰è®ºæ–‡æ•°é‡"""
        try:
            with open(self.readme_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å®šä¹‰æ‰€æœ‰å­åˆ†ç±»
            subcategories = [
                "Cybersecurity Evaluation Benchmarks",
                "Fine-tuned Domain LLMs for Cybersecurity", 
                "Threat Intelligence",
                "FUZZ",
                "Vulnerabilities Detection",
                "Insecure code Generation",
                "Program Repair", 
                "Anomaly Detection",
                "LLM Assisted Attack",
                "Others",
                "Further Research: Agent4Cybersecurity"
            ]
            
            counts = {}
            total = 0
            
            for subcategory in subcategories:
                pattern = self._build_section_pattern(subcategory)
                match = re.search(pattern, content, re.MULTILINE | re.DOTALL)
                
                if match:
                    section_content = match.group(1)
                    numbers = self._get_existing_paper_numbers(section_content)
                    count = len(numbers)
                    counts[subcategory] = count
                    total += count
                else:
                    counts[subcategory] = 0
            
            counts['total'] = total
            self.logger.info(f"ç°æœ‰è®ºæ–‡ç»Ÿè®¡å®Œæˆï¼Œæ€»è®¡: {total} ç¯‡")
            
            return counts
            
        except Exception as e:
            self.logger.error(f"ç»Ÿè®¡ç°æœ‰è®ºæ–‡å¤±è´¥: {e}")
            return {}
    
    def preview_changes(self, papers_by_category: Dict[str, List[ProcessedPaper]]) -> str:
        """é¢„è§ˆå°†è¦è¿›è¡Œçš„æ›´æ”¹"""
        preview = ["=== é¢„è§ˆå°†è¦æ·»åŠ çš„è®ºæ–‡ ===\n"]
        
        total_new_papers = 0
        for category_key, papers in papers_by_category.items():
            if papers:
                _, subcategory = category_key.split('_', 1)
                preview.append(f"## {subcategory} ({len(papers)} ç¯‡)")
                
                for i, paper in enumerate(papers[:3], 1):  # åªæ˜¾ç¤ºå‰3ç¯‡
                    preview.append(f"  {i}. {paper.title[:80]}...")
                
                if len(papers) > 3:
                    preview.append(f"  ... è¿˜æœ‰ {len(papers) - 3} ç¯‡è®ºæ–‡")
                
                preview.append("")
                total_new_papers += len(papers)
        
        preview.append(f"æ€»è®¡å°†æ–°å¢: {total_new_papers} ç¯‡è®ºæ–‡")
        
        return "\n".join(preview)